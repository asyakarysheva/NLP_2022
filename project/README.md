# Ссылка на ноутбук в колабе (на всякий случай):

https://colab.research.google.com/drive/11tJDgx_fpaaFXg8Ky_Smjxcbxx3h2ekX#scrollTo=23oHlyiSOEAY

# Отчёт команды №5

## 1) Описание корпусов 
Объем тренировочного корпуса: 34848 токенов, 213 текстов.

Готовые модели, корпуса:
- новостной корпус Lenta.ru (Lenta.Ru-News-Dataset: https://www.kaggle.com/datasets/yutkin/corpus-of-russian-news-articles-from-lenta);
- тональный словарь КартаСловСент (https://github.com/dkulagin/kartaslov/tree/master/dataset/kartaslovsent);
- модель word2vec-ruscorpora-300 библиотеки gensim;
- модель FastTextSocialNetworkModel библиотеки dostoevsky.

## 2) Методы и признаки

- Контрастивный метод выделения аспектных n-грамм:

Нейтральный новостной корпус сравнивался с отзывами. Объём новостного корпуса при этом был ограничен до 7000 текстов. В текстах и исследуемого корпуса, и нейтрального корпуса были оставлены только существительные, глаголы и прилагательные. Тексты были лемматизированы. Для каждой леммы из корпуса отзывов считалась метрика weirdness.

- Дистрибутивная семантика как метод выделения аспектных n-грамм и приписывания им категорий:

С помощью векторной модели word2vec-ruscorpora-300 искались униграммы и биграммы, наиболее близкие к аспектным n-граммам, выделенным в тренировочной выборке. Аналогичная модель использовалась и для приписывания аспектной n-грамме одной из пяти категорий.

- Методы анализа тональности:

В качестве метода анализа тональности использовался лексических подход: аспектным униграммам, не встретившимся в обучающей выборке, тональность приписывалась согласно тональному словарю. 

Для определения тональности выделенных аспектных n-грамм, встретившихся в текстах тренировочных данных, использовалась модель FastTextSocialNetworkModel библиотеки dostoevsky: выделялись две правых и две левых по отношению к целевой n-грамме леммы, собранные пятиграммы подавались на вход нейросети.

## 3) Результаты, анализ ошибок

- Ошибки в ходе самой работы:

Сначала мы пытались найти упоминания с помощью word2vec, ища слова, наиболее похожие и на упоминания в тренировочной выборке, и на упоминания, полученные контрастивным методом. Но такой подход оказался не очень успешным: в итоге получилось не очень много осмысленных пар "упоминание-аспект" (даже при наличии порогового значения для косинусной близости).

По этой причине было решено опираться только на леммы в обучающих данных во время расширения списка упоминаний: эти леммы можно считать эталоном разметки, в отличие от лемм, полученных автоматически при сравнении отзывов с нейтральными текстами.

- Ошибки при оценке качества предсказаний:

При оценке предсказаний выяснилось, что accuracy по выделению упоминаний с категориями увеличилась относительно бейзлайна: Full match precision: 0.47345348270823184, Full match recall: 0.7391634980988593, Partial match ratio in pred: 0.6015586945932782, Full category accuracy: 0.4588407208962494, Partial category accuracy: 0.5830491962981004. Accuracy по тональности упоминаний также возросла (но скорее незначительно): accuracy по полностью совпавшим упоминаниям –  0.6790123456790124, accuracy по частично совпавшим упоминаниям –   0.5893536121673004.

Вместе с тем уменьшилась accuracy по тональности категории: на 0,01 по сравнению с бейзлайном. Снижение значения этой метрики говорит о том, что требуется более тщательно подходить к анализу тональности аспектных n-грамм и отнесению их к одной из предложенных категорий. Возможно, напротив, стоит изменить правила, согласно которым тональность приписывается категории.
